{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "63z7hfmFm7a9",
        "outputId": "149b03de-6e30-40f8-d22b-705c8067ebef"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      2\u001b[0m files\u001b[38;5;241m.\u001b[39mupload()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im7FpqCFoqor",
        "outputId": "182f8461-3688-46a1-f5e8-8965b5653520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC4ZcysHorei"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers tqdm scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYZ531vlp8r3"
      },
      "outputs": [],
      "source": [
        "!mkdir -p csv_data\n",
        "!mv sample_train.csv csv_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040x2GhlowoK",
        "outputId": "29693985-ae16-4312-b36b-db46e980e04a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'csv_data/sample_train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv_data/sample_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     df_processed \u001b[38;5;241m=\u001b[39m process_token_similarity(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilar\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_processed\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'csv_data/sample_train.csv'"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# function to compute cosine similarity between two code snippets\n",
        "def compute_cosine_similarity(code1, code2) -> float:\n",
        "\n",
        "    # Remove comments\n",
        "    code1 = re.sub(r'//.*?$|/\\*.*?\\*/', '', code1, flags=re.DOTALL | re.MULTILINE)\n",
        "    code2 = re.sub(r'//.*?$|/\\*.*?\\*/', '', code2, flags=re.DOTALL | re.MULTILINE)\n",
        "\n",
        "    # Remove whitespace\n",
        "    code1 = re.sub(r'\\s+', ' ', code1).strip()\n",
        "    code2 = re.sub(r'\\s+', ' ', code2).strip()\n",
        "\n",
        "    # Define custom token pattern for code\n",
        "    tokenPattern = \"\"\n",
        "    tokenPattern += r\"[A-Za-z_][A-Za-z0-9_]*\"  # Identifiers\n",
        "    tokenPattern += r\"|\\d+\"                     # Numbers\n",
        "    tokenPattern += r\"|==|!=|<=|>=|\\+=|-=|\\*=|/=|&&|\\|\\|\"  # Multi-char operators\n",
        "    tokenPattern += r\"|\\\".*?\\\"|\\'.*?\\'\"  # String literals\n",
        "    tokenPattern += r\"|[{}()\\[\\];=+\\-*/<>!&|]\"  # Single-char operators and punctuation\n",
        "\n",
        "    # Define stop words common in code\n",
        "    stopWords = [\"include\", \"namespace\", \"using\", \"std\", \"return\", \"cin\", \"cout\", \"int\", \"float\", \"double\", \"string\", \"bool\", \"endl\"]\n",
        "\n",
        "    # Compute TF-IDF vectors\n",
        "    vectorizer = TfidfVectorizer(token_pattern=tokenPattern, ngram_range=(1, 2), stop_words=stopWords, norm='l2', sublinear_tf=True)\n",
        "    tfidfMatrix = vectorizer.fit_transform([code1, code2])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarityMatrix = cosine_similarity(tfidfMatrix[0:1], tfidfMatrix[1:2])\n",
        "    similarityValue = similarityMatrix[0][0]\n",
        "\n",
        "    # Return similarity value\n",
        "    return similarityValue\n",
        "\n",
        "# function to process training data and compute similarity for each pair\n",
        "def process_token_similarity(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['token_similarity'] = df.apply(lambda row: compute_cosine_similarity(row['code1'], row['code2']), axis=1)\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    df = pd.read_csv(\"csv_data/sample_train.csv\")\n",
        "    df_processed = process_token_similarity(df[['code1', 'code2', 'similar']])\n",
        "    print(df_processed.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SGZ8UJ2eqHCc"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ast\n",
        "import math\n",
        "import time\n",
        "from typing import Any\n",
        "from difflib import SequenceMatcher\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Inputs\n",
        "inputs = [\n",
        "    \"hello\\nolleh\\n\",\n",
        "    \"0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n89\\n45\\n109\\n420\\n39\\n1\\n0\\n60\\n\",\n",
        "    \"100\\n99\\n98\\n97\\n96\\n95\\n94\\n93\\n92\\n91\\n90\\n\",\n",
        "    \"4\\nword1\\nword2\\nword3\\nword4\\n\",\n",
        "    \"cat\\n5\\n10\\n8\\n4\\n\",\n",
        "    \"0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n\",\n",
        "    \"3\\n5 6 7\\n1 2 3\\n\",\n",
        "    \"7\\n100 150 200\\n10 20 30 40 50 60 70\\n\",\n",
        "    \"4.5\\n10.9\\n2.3\\n8.9\\n18.49\\n29.82\\n22.22\\n14.00\\n6.89\\n\",\n",
        "    \"-8\\n-12\\n-5\\n-11\\n-4\\n-2\\n-32\\n-450\\n-20\\n-89\\n\"\n",
        "    \"apple\\nbanana\\ncat\\ndog\\nzebra\\nalpha\\nomega\\ntest\\nhello\\nworld\\n\"\n",
        "]\n",
        "inputs = [x.encode('utf-8') for x in inputs]\n",
        "\n",
        "# Compare String\n",
        "def _string_similarity(a: str, b: str) -> float:\n",
        "    return SequenceMatcher(a=a, b=b).ratio()\n",
        "\n",
        "# Check if number\n",
        "def is_number(x):\n",
        "    try:\n",
        "        result = float(x)\n",
        "\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Determine the similarity of 2 numbers\n",
        "def _numeric_similarity(out1: float, out2: float) -> float:\n",
        "    if out1 == out2:\n",
        "        return 1.0\n",
        "    # NaN type\n",
        "    elif math.isnan(out1) or math.isnan(out2):\n",
        "        if (math.isnan(out1) and not math.isnan(out2)) or (not math.isnan(out1) and math.isnan(out2)):\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 1.0\n",
        "    # Large / infinite numbers\n",
        "    elif math.isinf(out1) or math.isinf(out2):\n",
        "        if (math.isinf(out1) and not math.isinf(out2)) or (not math.isinf(out1) and math.isinf(out2)):\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 1.0\n",
        "\n",
        "\n",
        "    # Find absolute distance between highest and smallest number\n",
        "    out1 = abs(out1)\n",
        "    out2 = abs(out2)\n",
        "    highest = max(out1, out2)\n",
        "\n",
        "    # Avoid division by 0\n",
        "    if highest == 0:\n",
        "        highest = 0.1\n",
        "    smallest = min(out1, out2)\n",
        "    distance = abs(highest - smallest)\n",
        "\n",
        "    # Normalize the distance the numbers to a range of [0-1]\n",
        "    normalizedDistance = np.round(1 - (distance / abs(highest)), decimals=3)\n",
        "    # print(f\"Normalized dist {out1} {out2} {normalizedDistance}\")\n",
        "    return normalizedDistance\n",
        "\n",
        "# Parse into json, list, or hash/dict\n",
        "def try_parse(s):\n",
        "    # Try JSON\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Try Python literal (e.g. \"[1,2,3]\" or \"{'a': 2}\")\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Try to break into list if separated by spaces\n",
        "    try:\n",
        "        if \" \" in s:\n",
        "            return s.split()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return s\n",
        "\n",
        "# Compare lists\n",
        "def listSimilarity(output1: list, output2: list) -> float:\n",
        "    try:\n",
        "        if not isinstance(output1, list) or not isinstance(output2, list):\n",
        "            return 0.0\n",
        "        listLength = min(len(output1), len(output2))\n",
        "        if listLength <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        outputScore = 0\n",
        "        for i in range(0, listLength):\n",
        "\n",
        "            o1 = try_parse(output1[i])\n",
        "            o2 = try_parse(output2[i])\n",
        "\n",
        "            if o1 is None or o2 is None:\n",
        "                outputScore += noneSim(o1, o2)\n",
        "\n",
        "            elif isinstance(o1, list) or isinstance(o2, list):\n",
        "                outputScore += listSimilarity(o1, o2)\n",
        "\n",
        "            elif isinstance(o1, dict) or isinstance(o2, dict):\n",
        "                outputScore += 1.0 if o1 == o2 else 0.0\n",
        "\n",
        "            elif is_number(o1) and is_number(o2):\n",
        "                outputScore += _numeric_similarity(float(o1), float(o2))\n",
        "\n",
        "            # Nan Character\n",
        "            elif '\\ufffd' in text1 or  '\\ufffd' in text2:\n",
        "                if ('\\ufffd' in text1 and '\\ufffd' not in text2) or ('\\ufffd' not in text1 and '\\ufffd' in text2) :\n",
        "                    outputScore += 0.0\n",
        "                else:\n",
        "                    outputScore += 1.0\n",
        "\n",
        "            else:\n",
        "                outputScore += _string_similarity(o1, o2)\n",
        "\n",
        "        return outputScore / listLength\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Compare None types\n",
        "def noneSim(out1: Any, out2: Any)-> float:\n",
        "\n",
        "    if (out1 == 0 and out2 is None) or (out2 == 0 and out1 is None):\n",
        "        return 0.9\n",
        "\n",
        "    elif(out1 is None and out2 == '') or (out2 is None and out1 == ''):\n",
        "        return 0.9\n",
        "\n",
        "    elif out1 is None and out2 is None:\n",
        "        return 1.0\n",
        "\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "# Compare logic\n",
        "def compare(raw1: bytes, text1: str, raw2: bytes, text2: str) -> float:\n",
        "    try:\n",
        "\n",
        "        # Compare raw bytes\n",
        "        if raw1 == raw2:\n",
        "            return 1.0\n",
        "\n",
        "        # try to parse into a dict or list\n",
        "        text1 = try_parse(text1)\n",
        "        text2 = try_parse(text2)\n",
        "\n",
        "        # None type\n",
        "        if text1 is None or text2 is None:\n",
        "            return noneSim(text1, text2)\n",
        "\n",
        "        # List\n",
        "        elif isinstance(text1, list) or isinstance(text2, list):\n",
        "            return listSimilarity(text1, text2)\n",
        "\n",
        "        # Dict\n",
        "        elif isinstance(text1, dict) or isinstance(text2, dict):\n",
        "            return 1.0 if text1 == text2 else 0.0\n",
        "\n",
        "        # Numbers\n",
        "        elif is_number(text1) and is_number(text2):\n",
        "            return _numeric_similarity(float(text1), float(text2))\n",
        "\n",
        "            # Nan Character\n",
        "        elif '\\ufffd' in text1 or  '\\ufffd' in text2:\n",
        "            if ('\\ufffd' in text1 and '\\ufffd' not in text2) or ('\\ufffd' not in text1 and '\\ufffd' in text2) :\n",
        "                return 0.0\n",
        "            else:\n",
        "                return 1.0\n",
        "        # String\n",
        "        else:\n",
        "            return _string_similarity(text1, text2)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Compile and run the cpp program pair\n",
        "def run (fName1: str, fName2: str, code1: str, code2: str, tmpdir) -> list:\n",
        "\n",
        "    try:\n",
        "        # --- Write C++ file ---\n",
        "        with open(fName1, \"w\") as f:\n",
        "            f.write(code1)\n",
        "\n",
        "        with open(fName2, \"w\") as f:\n",
        "            f.write(code2)\n",
        "\n",
        "        exe1 = fName1.replace(\".cpp\", \"\")\n",
        "        exe2 = fName2.replace(\".cpp\", \"\")\n",
        "\n",
        "        # --- Compile ---\n",
        "        compile_proc1 = subprocess.run(\n",
        "            [\"g++\", fName1, \"-o\", exe1],\n",
        "            text=False,\n",
        "            capture_output=False,\n",
        "            stdin=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL,\n",
        "            check=False\n",
        "        )\n",
        "        # --- Compile ---\n",
        "        compile_proc2 = subprocess.run(\n",
        "            [\"g++\", fName2, \"-o\", exe2],\n",
        "            text=False,\n",
        "            capture_output=False,\n",
        "            stdin=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL,\n",
        "            check=False\n",
        "        )\n",
        "\n",
        "        # Compilation failed\n",
        "        if compile_proc1.returncode != 0 and compile_proc2.returncode !=0:\n",
        "            return 1\n",
        "        elif (compile_proc1.returncode != 0 and compile_proc2.returncode == 0) or ( compile_proc2.returncode != 0 and compile_proc1.returncode == 0):\n",
        "            return 0\n",
        "\n",
        "        outputs = 0\n",
        "        # --- Run with series of inputs---\n",
        "        for input in inputs:\n",
        "            # Run code 1\n",
        "            try:\n",
        "                out1 = subprocess.run(\n",
        "                    [exe1],\n",
        "                    input=input,\n",
        "                    capture_output=True,\n",
        "                    text=False,\n",
        "                    check=True,\n",
        "                    timeout=0.5,\n",
        "                    cwd=tmpdir\n",
        "                )\n",
        "                raw1 = out1.stdout\n",
        "                text1 = raw1.decode(\"utf-8\", errors=\"replace\").replace(\"\\n\", \" \")\n",
        "            # Catch error in program\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                raw1 = None\n",
        "                text1 = None\n",
        "            # Program was not given enough inputs\n",
        "            except subprocess.TimeoutExpired as e:\n",
        "                raw1 = None\n",
        "                text1 = None\n",
        "            # Run code2\n",
        "            try:\n",
        "                out2 = subprocess.run(\n",
        "                    [exe2],\n",
        "                    input=input,\n",
        "                    capture_output=True,\n",
        "                    text=False,\n",
        "                    check=True,\n",
        "                    timeout=0.5,\n",
        "                    cwd=tmpdir\n",
        "                )\n",
        "                raw2 = out2.stdout\n",
        "                text2 = raw2.decode(\"utf-8\", errors=\"replace\").replace(\"\\n\", \" \")\n",
        "            # Catch error in program\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                raw2 = None\n",
        "                text2 = None\n",
        "            # Program was not given enough inputs\n",
        "            except subprocess.TimeoutExpired as e:\n",
        "                raw2 = None\n",
        "                text2 = None\n",
        "\n",
        "            outputs += compare(raw1, text1, raw2, text2)\n",
        "\n",
        "        score = round((outputs / len(inputs)), 2)\n",
        "        return score\n",
        "\n",
        "    except Exception as err:\n",
        "        print(f\"Error in file running {err}\")\n",
        "        return 0\n",
        "\n",
        "# Process each code pair in a pandas dataframe\n",
        "def process(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    n = len(df)\n",
        "\n",
        "    if n == 0:\n",
        "        df[\"output_similarity\"] = []\n",
        "        return df\n",
        "\n",
        "    results = np.zeros(n, dtype=float)\n",
        "\n",
        "    # Run files in a sandboxed environment\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        for i in tqdm(range(0, n), desc=\"output similarity\"):\n",
        "            fName1 = os.path.join(tmpdir, f\"prog_1.cpp\")\n",
        "            fName2 = os.path.join(tmpdir, f\"prog_2.cpp\")\n",
        "            code1 = df['code1'].iloc[i]\n",
        "            code2 =   df['code2'].iloc[i]\n",
        "\n",
        "            outputSim = run (fName1, fName2, code1, code2, tmpdir)\n",
        "            results[i] = outputSim\n",
        "\n",
        "    df[\"output_similarity\"] = results\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsIKWQlvKVJ",
        "outputId": "3db94df6-31bd-41bc-dadd-c1d88e327f99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# import necessary libraries\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import time\n",
        "from typing import Iterable, Optional\n",
        "\n",
        "# set device and configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "use_fp16 = torch.cuda.is_available() and device.type == 'cuda'\n",
        "last_n_layers_default = 4\n",
        "kw_default = 0.3\n",
        "default_layer_pooling = False\n",
        "combine_method_default = 'prod'\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('microsoft/graphcodebert-base')\n",
        "# load model with hidden states enabled for optional layer pooling\n",
        "model = RobertaModel.from_pretrained('microsoft/graphcodebert-base', output_hidden_states=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# function to compute keyword overlap\n",
        "def keyword_overlap(code1, code2):\n",
        "    keywords = [\n",
        "        \"for\", \"while\", \"if\", \"else\", \"return\", \"int\", \"float\", \"double\",\n",
        "        \"string\", \"bool\", \"class\", \"def\", \"import\", \"include\", \"namespace\",\n",
        "        \"using\", \"public\", \"private\", \"protected\", \"void\", \"static\", \"try\",\n",
        "        \"catch\", \"switch\", \"case\", \"break\", \"continue\"\n",
        "    ]\n",
        "\n",
        "    k1 = set([k for k in keywords if k in code1])   # Extract keywords from code1\n",
        "    k2 = set([k for k in keywords if k in code2])   # Extract keywords from code2\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if not k1 or not k2:\n",
        "        return kw_default\n",
        "\n",
        "    # Compute Jaccard similarity\n",
        "    return len(k1.intersection(k2)) / max(len(k1), len(k2))\n",
        "\n",
        "# function to normalize code snippets\n",
        "def perform_normalization(code: str) -> str:\n",
        "    # Remove comments and collapse whitespace\n",
        "    code = re.sub(r'//.*?$|/\\*.*?\\*/', '', code, flags=re.DOTALL | re.MULTILINE)\n",
        "\n",
        "    # remove common preprocessor/import lines\n",
        "    lines = code.splitlines()\n",
        "    kept = []\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "        if stripped.startswith('#include'):\n",
        "            continue\n",
        "        if stripped.startswith('using namespace'):\n",
        "            continue\n",
        "        if stripped.startswith('typedef'):\n",
        "            continue\n",
        "        if stripped.startswith('#define'):\n",
        "            continue\n",
        "\n",
        "        if not stripped:\n",
        "            continue\n",
        "        kept.append(stripped)\n",
        "\n",
        "    code = \"\\n\".join(kept)\n",
        "\n",
        "    # compress whitespace\n",
        "    code = re.sub(r'\\s+', ' ', code).strip()\n",
        "\n",
        "    return code\n",
        "\n",
        "\n",
        "# function for mean pooling\n",
        "def mean_pooling(last_hidden_state, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    summed = (last_hidden_state * mask).sum(dim=1)\n",
        "    counts = mask.sum(dim=1).clamp(min=1e-9)\n",
        "    return summed / counts\n",
        "\n",
        "# function for layer-averaged pooling\n",
        "def layer_average_pooling(hidden_states, attention_mask, last_n_layers):\n",
        "    layers = hidden_states[-last_n_layers:]\n",
        "    pooled_layers = []\n",
        "    for layer in layers:\n",
        "        pooled_layer = mean_pooling(layer, attention_mask)\n",
        "        pooled_layers.append(pooled_layer)\n",
        "    return torch.stack(pooled_layers, dim=0).mean(dim=0)\n",
        "\n",
        "# function to compute code embeddings\n",
        "def compute_embedding(codes: Iterable[str], batch_size: int = 32, max_length: int = 64, normalize: bool = True,\n",
        "                      layer_pooling: Optional[bool] = None, last_n_layers: int = 4):\n",
        "    \"\"\"Compute embeddings for `codes` with optional layer-averaged pooling.\n",
        "\n",
        "    Args:\n",
        "        codes: iterable of strings (or a single string will be supported by caller).\n",
        "        batch_size: tokenization / model batch size.\n",
        "        max_length: tokenizer max length.\n",
        "        layer_pooling: if True, average the last `last_n_layers` hidden states (mean pooling per layer then average).\n",
        "        last_n_layers: number of last layers to average when `layer_pooling` is True.\n",
        "    Returns:\n",
        "        Torch tensor of shape (N, hidden_size) on CPU (L2-normalized rows).\n",
        "    \"\"\"\n",
        "    # allow single string too\n",
        "    single = False\n",
        "    single_input = isinstance(codes, str)\n",
        "    if single_input:\n",
        "        single = True\n",
        "        codes = [codes]\n",
        "\n",
        "    all_embs = []\n",
        "\n",
        "    if layer_pooling is None:\n",
        "        layer_pooling = default_layer_pooling\n",
        "\n",
        "    for i in range(0, len(codes), batch_size):\n",
        "        batch_texts = [perform_normalization(c) for c in codes[i:i + batch_size]]\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if use_fp16:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    out = model(**inputs)\n",
        "            else:\n",
        "                out = model(**inputs)\n",
        "\n",
        "\n",
        "        if layer_pooling:\n",
        "            hidden_states = out.hidden_states\n",
        "            embeddings = layer_average_pooling(hidden_states, inputs['attention_mask'], last_n_layers)\n",
        "        else:\n",
        "            embeddings = mean_pooling(out.last_hidden_state, inputs['attention_mask'])\n",
        "\n",
        "\n",
        "        if normalize:\n",
        "            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
        "        all_embs.append(embeddings.cpu())\n",
        "\n",
        "\n",
        "    if all_embs:\n",
        "        result = torch.cat(all_embs, dim=0).numpy()\n",
        "    else:\n",
        "        result = np.zeros((0, model.config.hidden_size), dtype=np.float32)\n",
        "\n",
        "    if single:\n",
        "        return embeddings[0]\n",
        "    return result\n",
        "\n",
        "# function to compute semantic similarity between two code embeddings\n",
        "def compute_semantic_similarity(vec1, vec2):\n",
        "\n",
        "    # for 1d scalars\n",
        "    if vec1.ndim == 1 and vec2.dim == 1:\n",
        "        v1 = vec1.astype(np.float32)\n",
        "        v2 = vec2.astype(np.float32)\n",
        "\n",
        "        denominator = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
        "        if denominator == 0:\n",
        "            return 0.0\n",
        "        return float(np.dot(v1, v2) / denominator)\n",
        "\n",
        "\n",
        "    # for 2d arrays\n",
        "    if vec1.ndim == 1:\n",
        "        vec1 = vec1[None, :]\n",
        "    if vec2.ndim == 1:\n",
        "        vec2 = vec2[None, :]\n",
        "\n",
        "\n",
        "    v1 = vec1.astype(np.float32)\n",
        "    v2 = vec2.astype(np.float32)\n",
        "\n",
        "    v1_norms = np.linalg.norm(v1, axis=1, keepdims=True).clip(min=1e-9)\n",
        "    v2_norms = np.linalg.norm(v2, axis=1, keepdims=True).clip(min=1e-9)\n",
        "\n",
        "    v1 = v1 / v1_norms\n",
        "    v2 = v2 / v2_norms\n",
        "\n",
        "    # general case: (N, d) x (M, d) -> (N, M) matrix\n",
        "    return np.matmul(v1, v2.T)\n",
        "\n",
        "# function to process training data and compute similarity for each pair\n",
        "def process_semantic_similarity(df, pair_batch_size: int = 128, embed_batch_size: int = 32, combine_method: Optional[str] = None, alpha: float = 0.85, rescale: bool = False):\n",
        "    \"\"\"Compute semantic similarity for each row in `df` by processing pairs in chunks.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with columns `code1` and `code2`.\n",
        "        pair_batch_size: number of pairs to process in each chunk (controls memory footprint).\n",
        "        embed_batch_size: batch size passed to `compute_embedding` for tokenization/model batching.\n",
        "\n",
        "    Returns:\n",
        "        Copy of `df` with a new column `semantic_similarity`.\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "    n = len(df)\n",
        "    if n == 0:\n",
        "        df['semantic_similarity'] = []\n",
        "        return df\n",
        "\n",
        "    results = np.zeros(n, dtype=float)\n",
        "\n",
        "    effective_combine = combine_method if combine_method is not None else combine_method_default\n",
        "\n",
        "    # iterate over pairs in chunks\n",
        "    for start in tqdm(range(0, n, pair_batch_size), desc=\"pair-chunks\"):\n",
        "        end = min(start + pair_batch_size, n)\n",
        "\n",
        "        # normalize code snippets in the chunk\n",
        "        codes1_chunk = df['code1'].iloc[start:end].astype(str).tolist()\n",
        "        codes2_chunk = df['code2'].iloc[start:end].astype(str).tolist()\n",
        "\n",
        "        # embed each chunk (embedding function itself can batch internally)\n",
        "        # enable layer pooling and match optimized defaults for parity\n",
        "        emb1 = compute_embedding(codes1_chunk, batch_size=embed_batch_size, layer_pooling=True, last_n_layers=4, max_length=64)\n",
        "        emb2 = compute_embedding(codes2_chunk, batch_size=embed_batch_size, layer_pooling=True, last_n_layers=4, max_length=64)\n",
        "\n",
        "        # compute semantic similarities for the chunk\n",
        "        sims = compute_semantic_similarity(emb1, emb2)\n",
        "\n",
        "        if sims.shape[0] == sims.shape[1]:\n",
        "            sims = np.diagonal(sims)\n",
        "        else:\n",
        "            # If pair counts match, prefer diagonal; else use row-wise max\n",
        "            if sims.shape[0] == (end - start) and sims.shape[1] == (end - start):\n",
        "                sims = np.diag(sims)\n",
        "            else:\n",
        "                sims = np.max(sims, axis=1)\n",
        "\n",
        "        kw = np.array([keyword_overlap(a, b) for a, b in zip(codes1_chunk, codes2_chunk)], dtype=float)\n",
        "\n",
        "        print(f\"Semantic sims (first 10): {sims[:10]}\")\n",
        "        print(f\"Keyword overlaps (first 10): {kw[:10]}\")\n",
        "        if effective_combine == 'prod':\n",
        "            combined = sims * kw\n",
        "        elif effective_combine == 'avg':\n",
        "            combined = 0.5 * (sims + kw)\n",
        "        elif effective_combine == 'weighted':\n",
        "            combined = alpha * sims + (1 - alpha) * kw\n",
        "        else:\n",
        "            raise ValueError(f'Unknown combine method: {effective_combine}')\n",
        "\n",
        "        if rescale:\n",
        "            combined = np.clip(combined, -1.0, 1.0)\n",
        "            combined = (combined + 1.0) / 2.0\n",
        "\n",
        "        results[start:end] = combined\n",
        "\n",
        "    df['semantic_similarity'] = results\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heRlt2WuqQPh"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT7VxmjJVrVs"
      },
      "source": [
        "##Ensemble Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7zWvLSCykFqp"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'process_token_similarity' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[0;32m----> 8\u001b[0m add_token_sim \u001b[38;5;241m=\u001b[39m process_token_similarity\n\u001b[1;32m      9\u001b[0m add_semantic_sim \u001b[38;5;241m=\u001b[39m process_semantic_similarity\n\u001b[1;32m     10\u001b[0m add_output_sim \u001b[38;5;241m=\u001b[39m process\n",
            "\u001b[0;31mNameError\u001b[0m: name 'process_token_similarity' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "add_token_sim = process_token_similarity\n",
        "add_semantic_sim = process_semantic_similarity\n",
        "add_output_sim = process\n",
        "\n",
        "# MLP\n",
        "class EnsembleMLP(nn.Module):\n",
        "    def __init__(self, inputSize = 3, hiddenSize = 16, outputSize = 1):\n",
        "        super(EnsembleMLP, self).__init__()\n",
        "        self.network = nn.Sequential(nn.Linear(inputSize,hiddenSize), nn.ReLU(), nn.Linear(hiddenSize,hiddenSize), nn.ReLU(), nn.Linear(hiddenSize,outputSize))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "    def predictProba(self,x):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = self.forward(x)\n",
        "            return torch.sigmoid(logits)\n",
        "\n",
        "def buildXAndY_real(sample_train_path=\"sample_train.csv\", limit=None):\n",
        "    df = pd.read_csv(sample_train_path)\n",
        "\n",
        "    if limit is not None:\n",
        "        df = df.head(limit)\n",
        "\n",
        "    df = df[[\"code1\", \"code2\", \"similar\"]].copy()\n",
        "\n",
        "    df = add_token_sim(df)\n",
        "    df = add_semantic_sim(df)\n",
        "    df = add_output_sim(df)\n",
        "\n",
        "    print(\"Columns after similarity scripts:\", df.columns.tolist())\n",
        "\n",
        "    X = df[[\"token_similarity\", \"semantic_similarity\", \"output_similarity\"]].astype(np.float32).to_numpy()\n",
        "    y = df[\"similar\"].astype(np.float32).to_numpy()\n",
        "    return X, y, df\n",
        "\n",
        "def trainEnsemble(X, y):\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "  X_train = torch.FloatTensor(X_train)\n",
        "  y_train = torch.FloatTensor(y_train)\n",
        "  X_val = torch.FloatTensor(X_val)\n",
        "  y_val = torch.FloatTensor(y_val)\n",
        "\n",
        "  model = EnsembleMLP()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  bestValLoss = float('inf')\n",
        "  patience = 10\n",
        "  patienceCount = 0\n",
        "  for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train)\n",
        "    loss = criterion(logits.squeeze(), y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_logits = model(X_val)\n",
        "      val_loss = criterion(val_logits.squeeze(), y_val)\n",
        "      val_losses.append(val_loss.item())\n",
        "\n",
        "    if (val_loss < bestValLoss):\n",
        "      bestValLoss = val_loss\n",
        "      patienceCount = 0\n",
        "      torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "      patienceCount += 1\n",
        "    if patienceCount >= patience:\n",
        "      print(f\"Early stopping at {epoch}\")\n",
        "      break\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch {epoch}: Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "  return model, train_losses, val_losses\n",
        "\n",
        "# Inference\n",
        "def predict(model, X, threshold=0.7):\n",
        "  model.eval()\n",
        "  X = torch.FloatTensor(X)  # convert if numpy\n",
        "  with torch.no_grad():\n",
        "    probabilities = model.predictProba(X).squeeze()\n",
        "    predictions = (probabilities >= threshold).float()\n",
        "    return probabilities.numpy(), predictions.numpy()\n",
        "def evaluate(y_true, y_pred):\n",
        "  print(\"\\n--- TEST RESULTS (threshold=0.7) ---\")\n",
        "  print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
        "  print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0))\n",
        "  print(\"Recall   :\", recall_score(y_true, y_pred, zero_division=0))\n",
        "  print(\"F1       :\", f1_score(y_true, y_pred, zero_division=0))\n",
        "  print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567,
          "referenced_widgets": [
            "b9ffa9576b6841d89e9f14cfd17e063f",
            "5d3568177d344687a5193c367047de47",
            "806d673a1eb74a24ba67bddcc52e7d03",
            "bc94ea1a06be47b2b996d902f5b01472",
            "2a9b0644dc104b969210e5ee861ebeb6",
            "c44b90f4642b4c48b20ed648e8184f1c",
            "7e4015b6313e435b85528bb204ee280e",
            "241f4c2266a2471a99dd06f33701efd5",
            "13ca60246ec74cee95dd4843853f506f",
            "fbdae5f344534d219d661a9e44e17e06",
            "a12bf09b29b04a55b3c58d2f81ffb2d1",
            "9fea11b734d94a61aec7e7891e5731d3",
            "dd1524ada8ce4b7093d5fec11e5ff9d2",
            "2206a5535c244cf5ac67181bd2b2d485",
            "452f2f939f13456f95f9f5104054ca48",
            "c98b5f6e3eb14ce8b63f297f2e9a7de8",
            "1f2cc53368e54292b5916745bf569d6e",
            "6dbfb761ef8a4afaa77db94a935cd075",
            "cdfccab8b65542fda9aac8b702e277fd",
            "83798855fd384836b53e11a854c4f521",
            "b6e3e8640dd042e99ab6432898b19ea2",
            "efff2e32cef1453f9f9482c1e8ae1e31"
          ]
        },
        "id": "Iyqc2HSPwY1e",
        "outputId": "7eb9ed9f-c94b-4634-ed09-4276a0e1c527"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9ffa9576b6841d89e9f14cfd17e063f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pair-chunks:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic sims (first 10): [0.9557072  0.9744534  0.9320595  0.95392996 0.9230163  0.9276461\n",
            " 0.9539391  0.9318732  0.9069919  0.8885174 ]\n",
            "Keyword overlaps (first 10): [0.75       0.88888889 0.66666667 0.45454545 0.72727273 0.5\n",
            " 0.8        0.7        0.75       0.58333333]\n",
            "Semantic sims (first 10): [0.9507477  0.9095962  0.9240067  0.87895566 0.94044447 0.9493807\n",
            " 0.95329225 0.9216672  0.93005013 0.9818524 ]\n",
            "Keyword overlaps (first 10): [0.77777778 0.8        0.66666667 0.7        0.7        0.57142857\n",
            " 0.77777778 0.90909091 0.88888889 1.        ]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fea11b734d94a61aec7e7891e5731d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "output similarity:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns after similarity scripts: ['code1', 'code2', 'similar', 'token_similarity', 'semantic_similarity', 'output_similarity']\n",
            "Epoch 0: Train Loss: 0.6741, Val Loss: 0.6636\n",
            "Epoch 10: Train Loss: 0.6615, Val Loss: 0.6456\n",
            "Epoch 20: Train Loss: 0.6490, Val Loss: 0.6277\n",
            "Epoch 30: Train Loss: 0.6356, Val Loss: 0.6084\n",
            "Epoch 40: Train Loss: 0.6211, Val Loss: 0.5872\n",
            "Epoch 50: Train Loss: 0.6050, Val Loss: 0.5639\n",
            "Epoch 60: Train Loss: 0.5871, Val Loss: 0.5380\n",
            "Epoch 70: Train Loss: 0.5666, Val Loss: 0.5082\n",
            "Epoch 80: Train Loss: 0.5438, Val Loss: 0.4762\n",
            "Epoch 90: Train Loss: 0.5196, Val Loss: 0.4405\n",
            "\n",
            "--- TEST RESULTS (threshold=0.7) ---\n",
            "Accuracy : 0.8\n",
            "Precision: 1.0\n",
            "Recall   : 0.5555555555555556\n",
            "F1       : 0.7142857142857143\n",
            "Confusion matrix:\n",
            " [[22  0]\n",
            " [ 8 10]]\n"
          ]
        }
      ],
      "source": [
        "X, y, df_feat = buildXAndY_real(\"csv_data/sample_train.csv\", limit=200)\n",
        "\n",
        "# train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# train\n",
        "model, train_losses, val_losses = trainEnsemble(X_train, y_train)\n",
        "\n",
        "# test with threshold 0.7\n",
        "probs, preds = predict(model, X_test, threshold=0.7)\n",
        "evaluate(y_test, preds)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13ca60246ec74cee95dd4843853f506f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f2cc53368e54292b5916745bf569d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2206a5535c244cf5ac67181bd2b2d485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdfccab8b65542fda9aac8b702e277fd",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83798855fd384836b53e11a854c4f521",
            "value": 200
          }
        },
        "241f4c2266a2471a99dd06f33701efd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9b0644dc104b969210e5ee861ebeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452f2f939f13456f95f9f5104054ca48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6e3e8640dd042e99ab6432898b19ea2",
            "placeholder": "",
            "style": "IPY_MODEL_efff2e32cef1453f9f9482c1e8ae1e31",
            "value": "200/200[11:36&lt;00:00,2.58s/it]"
          }
        },
        "5d3568177d344687a5193c367047de47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c44b90f4642b4c48b20ed648e8184f1c",
            "placeholder": "",
            "style": "IPY_MODEL_7e4015b6313e435b85528bb204ee280e",
            "value": "pair-chunks:100%"
          }
        },
        "6dbfb761ef8a4afaa77db94a935cd075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4015b6313e435b85528bb204ee280e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806d673a1eb74a24ba67bddcc52e7d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241f4c2266a2471a99dd06f33701efd5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13ca60246ec74cee95dd4843853f506f",
            "value": 2
          }
        },
        "83798855fd384836b53e11a854c4f521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fea11b734d94a61aec7e7891e5731d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd1524ada8ce4b7093d5fec11e5ff9d2",
              "IPY_MODEL_2206a5535c244cf5ac67181bd2b2d485",
              "IPY_MODEL_452f2f939f13456f95f9f5104054ca48"
            ],
            "layout": "IPY_MODEL_c98b5f6e3eb14ce8b63f297f2e9a7de8"
          }
        },
        "a12bf09b29b04a55b3c58d2f81ffb2d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6e3e8640dd042e99ab6432898b19ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ffa9576b6841d89e9f14cfd17e063f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d3568177d344687a5193c367047de47",
              "IPY_MODEL_806d673a1eb74a24ba67bddcc52e7d03",
              "IPY_MODEL_bc94ea1a06be47b2b996d902f5b01472"
            ],
            "layout": "IPY_MODEL_2a9b0644dc104b969210e5ee861ebeb6"
          }
        },
        "bc94ea1a06be47b2b996d902f5b01472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbdae5f344534d219d661a9e44e17e06",
            "placeholder": "",
            "style": "IPY_MODEL_a12bf09b29b04a55b3c58d2f81ffb2d1",
            "value": "2/2[01:21&lt;00:00,38.82s/it]"
          }
        },
        "c44b90f4642b4c48b20ed648e8184f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98b5f6e3eb14ce8b63f297f2e9a7de8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdfccab8b65542fda9aac8b702e277fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1524ada8ce4b7093d5fec11e5ff9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f2cc53368e54292b5916745bf569d6e",
            "placeholder": "",
            "style": "IPY_MODEL_6dbfb761ef8a4afaa77db94a935cd075",
            "value": "outputsimilarity:100%"
          }
        },
        "efff2e32cef1453f9f9482c1e8ae1e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdae5f344534d219d661a9e44e17e06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
